{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Building the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense , Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#STEP 1 - Convolution\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3),\n",
    "                      input_shape= (64,64,3), activation=\"relu\"))\n",
    "#STEP 2 - Max Pooling\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#STEP 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#STEP 4 - Full conection\n",
    "classifier.add(Dense(units=128, activation=\"relu\"))\n",
    "classifier.add(Dense(units=1, activation=\"sigmoid\")) #Perro o no perro.\n",
    "\n",
    "#Compile the neural network \n",
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) #Por solo terner 2 clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 - Adjusting the CNN to the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Program Files\\Python310\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.6529 - accuracy: 0.6280WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
      "250/250 [==============================] - 33s 129ms/step - loss: 0.6529 - accuracy: 0.6280 - val_loss: 0.5799 - val_accuracy: 0.7030\n",
      "Epoch 2/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.5796 - accuracy: 0.6961\n",
      "Epoch 3/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5604 - accuracy: 0.7051\n",
      "Epoch 4/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5366 - accuracy: 0.7283\n",
      "Epoch 5/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5345 - accuracy: 0.7324\n",
      "Epoch 6/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5178 - accuracy: 0.7369\n",
      "Epoch 7/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.4937 - accuracy: 0.7581\n",
      "Epoch 8/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.4774 - accuracy: 0.7665\n",
      "Epoch 9/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.4629 - accuracy: 0.7782\n",
      "Epoch 10/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.4467 - accuracy: 0.7821\n",
      "Epoch 11/200\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.4329 - accuracy: 0.7970\n",
      "Epoch 12/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.4274 - accuracy: 0.8021\n",
      "Epoch 13/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.4163 - accuracy: 0.8114\n",
      "Epoch 14/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3965 - accuracy: 0.8164\n",
      "Epoch 15/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3848 - accuracy: 0.8254\n",
      "Epoch 16/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3668 - accuracy: 0.8339\n",
      "Epoch 17/200\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.3605 - accuracy: 0.8400\n",
      "Epoch 18/200\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.3514 - accuracy: 0.8446\n",
      "Epoch 19/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3295 - accuracy: 0.8576\n",
      "Epoch 20/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3256 - accuracy: 0.8583\n",
      "Epoch 21/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.3225 - accuracy: 0.8609\n",
      "Epoch 22/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2959 - accuracy: 0.8754\n",
      "Epoch 23/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2997 - accuracy: 0.8685\n",
      "Epoch 24/200\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.2728 - accuracy: 0.8850\n",
      "Epoch 25/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2593 - accuracy: 0.8899\n",
      "Epoch 26/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2565 - accuracy: 0.8951\n",
      "Epoch 27/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2380 - accuracy: 0.9040\n",
      "Epoch 28/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2469 - accuracy: 0.8961\n",
      "Epoch 29/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2235 - accuracy: 0.9086\n",
      "Epoch 30/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2211 - accuracy: 0.9074\n",
      "Epoch 31/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.2066 - accuracy: 0.9168\n",
      "Epoch 32/200\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.2088 - accuracy: 0.9151\n",
      "Epoch 33/200\n",
      "250/250 [==============================] - 16s 63ms/step - loss: 0.1976 - accuracy: 0.9226\n",
      "Epoch 34/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.1819 - accuracy: 0.9256\n",
      "Epoch 35/200\n",
      "250/250 [==============================] - 16s 64ms/step - loss: 0.1827 - accuracy: 0.9305\n",
      "Epoch 36/200\n",
      "250/250 [==============================] - 15s 61ms/step - loss: 0.1743 - accuracy: 0.9320\n",
      "Epoch 37/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1792 - accuracy: 0.9286\n",
      "Epoch 38/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1572 - accuracy: 0.9383\n",
      "Epoch 39/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1574 - accuracy: 0.9380\n",
      "Epoch 40/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1594 - accuracy: 0.9358\n",
      "Epoch 41/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1459 - accuracy: 0.9440\n",
      "Epoch 42/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1475 - accuracy: 0.9433\n",
      "Epoch 43/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1423 - accuracy: 0.9452\n",
      "Epoch 44/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1415 - accuracy: 0.9446\n",
      "Epoch 45/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1288 - accuracy: 0.9507\n",
      "Epoch 46/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1238 - accuracy: 0.9525\n",
      "Epoch 47/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1298 - accuracy: 0.9526\n",
      "Epoch 48/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1190 - accuracy: 0.9546\n",
      "Epoch 49/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1226 - accuracy: 0.9521\n",
      "Epoch 50/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1267 - accuracy: 0.9531\n",
      "Epoch 51/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1027 - accuracy: 0.9617\n",
      "Epoch 52/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1181 - accuracy: 0.9535\n",
      "Epoch 53/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1189 - accuracy: 0.9542\n",
      "Epoch 54/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1047 - accuracy: 0.9629\n",
      "Epoch 55/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.1025 - accuracy: 0.9620\n",
      "Epoch 56/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0954 - accuracy: 0.9634\n",
      "Epoch 57/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0959 - accuracy: 0.9645\n",
      "Epoch 58/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0919 - accuracy: 0.9632\n",
      "Epoch 59/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0851 - accuracy: 0.9694\n",
      "Epoch 60/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0940 - accuracy: 0.9675\n",
      "Epoch 61/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0896 - accuracy: 0.9657\n",
      "Epoch 62/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0854 - accuracy: 0.9679\n",
      "Epoch 63/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0807 - accuracy: 0.9700\n",
      "Epoch 64/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1012 - accuracy: 0.9636\n",
      "Epoch 65/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0779 - accuracy: 0.9731\n",
      "Epoch 66/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0839 - accuracy: 0.9681\n",
      "Epoch 67/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0843 - accuracy: 0.9699\n",
      "Epoch 68/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0828 - accuracy: 0.9684\n",
      "Epoch 69/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0678 - accuracy: 0.9750\n",
      "Epoch 70/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0753 - accuracy: 0.9720\n",
      "Epoch 71/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0717 - accuracy: 0.9743\n",
      "Epoch 72/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0758 - accuracy: 0.9720\n",
      "Epoch 73/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0775 - accuracy: 0.9706\n",
      "Epoch 74/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0650 - accuracy: 0.9762\n",
      "Epoch 75/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0667 - accuracy: 0.9762\n",
      "Epoch 76/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0714 - accuracy: 0.9758\n",
      "Epoch 77/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0714 - accuracy: 0.9756\n",
      "Epoch 78/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0814 - accuracy: 0.9728\n",
      "Epoch 79/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0739 - accuracy: 0.9725\n",
      "Epoch 80/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0642 - accuracy: 0.9776\n",
      "Epoch 81/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0714 - accuracy: 0.9753\n",
      "Epoch 82/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0734 - accuracy: 0.9764\n",
      "Epoch 83/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0577 - accuracy: 0.9803\n",
      "Epoch 84/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0535 - accuracy: 0.9824\n",
      "Epoch 85/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0550 - accuracy: 0.9818\n",
      "Epoch 86/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0571 - accuracy: 0.9791\n",
      "Epoch 87/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0533 - accuracy: 0.9810\n",
      "Epoch 88/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0622 - accuracy: 0.9775\n",
      "Epoch 89/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0680 - accuracy: 0.9761\n",
      "Epoch 90/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0609 - accuracy: 0.9796\n",
      "Epoch 91/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0581 - accuracy: 0.9783\n",
      "Epoch 92/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0566 - accuracy: 0.9810\n",
      "Epoch 93/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0584 - accuracy: 0.9805\n",
      "Epoch 94/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0675 - accuracy: 0.9784\n",
      "Epoch 95/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0604 - accuracy: 0.9791\n",
      "Epoch 96/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0514 - accuracy: 0.9815\n",
      "Epoch 97/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0529 - accuracy: 0.9784\n",
      "Epoch 98/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0487 - accuracy: 0.9845\n",
      "Epoch 99/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0517 - accuracy: 0.9829\n",
      "Epoch 100/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0552 - accuracy: 0.9805\n",
      "Epoch 101/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0406 - accuracy: 0.9859\n",
      "Epoch 102/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0493 - accuracy: 0.9826\n",
      "Epoch 103/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0472 - accuracy: 0.9836\n",
      "Epoch 104/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0588 - accuracy: 0.9786\n",
      "Epoch 105/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0486 - accuracy: 0.9830\n",
      "Epoch 106/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0404 - accuracy: 0.9864\n",
      "Epoch 107/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0535 - accuracy: 0.9829\n",
      "Epoch 108/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0589 - accuracy: 0.9806\n",
      "Epoch 109/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0608 - accuracy: 0.9775\n",
      "Epoch 110/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0426 - accuracy: 0.9840\n",
      "Epoch 111/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0493 - accuracy: 0.9818\n",
      "Epoch 112/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0495 - accuracy: 0.9812\n",
      "Epoch 113/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0420 - accuracy: 0.9850\n",
      "Epoch 114/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0513 - accuracy: 0.9821\n",
      "Epoch 115/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0378 - accuracy: 0.9875\n",
      "Epoch 116/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0446 - accuracy: 0.9851\n",
      "Epoch 117/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0477 - accuracy: 0.9846\n",
      "Epoch 118/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0470 - accuracy: 0.9830\n",
      "Epoch 119/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0564 - accuracy: 0.9818\n",
      "Epoch 120/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0488 - accuracy: 0.9839\n",
      "Epoch 121/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0428 - accuracy: 0.9849\n",
      "Epoch 122/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0333 - accuracy: 0.9883\n",
      "Epoch 123/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0430 - accuracy: 0.9847\n",
      "Epoch 124/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0360 - accuracy: 0.9879\n",
      "Epoch 125/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0411 - accuracy: 0.9851\n",
      "Epoch 126/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0493 - accuracy: 0.9836\n",
      "Epoch 127/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0334 - accuracy: 0.9894\n",
      "Epoch 128/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0394 - accuracy: 0.9860\n",
      "Epoch 129/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0365 - accuracy: 0.9864\n",
      "Epoch 130/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0410 - accuracy: 0.9846\n",
      "Epoch 131/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0459 - accuracy: 0.9855\n",
      "Epoch 132/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0384 - accuracy: 0.9868\n",
      "Epoch 133/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0386 - accuracy: 0.9860\n",
      "Epoch 134/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0369 - accuracy: 0.9865\n",
      "Epoch 135/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0501 - accuracy: 0.9846\n",
      "Epoch 136/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0394 - accuracy: 0.9860\n",
      "Epoch 137/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0355 - accuracy: 0.9881\n",
      "Epoch 138/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0341 - accuracy: 0.9885\n",
      "Epoch 139/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0293 - accuracy: 0.9890\n",
      "Epoch 140/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 141/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0534 - accuracy: 0.9840\n",
      "Epoch 142/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0484 - accuracy: 0.9845\n",
      "Epoch 143/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0448 - accuracy: 0.9850\n",
      "Epoch 144/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0324 - accuracy: 0.9895\n",
      "Epoch 145/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0390 - accuracy: 0.9866\n",
      "Epoch 146/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0424 - accuracy: 0.9860\n",
      "Epoch 147/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0402 - accuracy: 0.9871\n",
      "Epoch 148/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 149/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0369 - accuracy: 0.9870\n",
      "Epoch 150/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0320 - accuracy: 0.9895\n",
      "Epoch 151/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0489 - accuracy: 0.9837\n",
      "Epoch 152/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0309 - accuracy: 0.9905\n",
      "Epoch 153/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0354 - accuracy: 0.9876\n",
      "Epoch 154/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0339 - accuracy: 0.9890\n",
      "Epoch 155/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0301 - accuracy: 0.9896\n",
      "Epoch 156/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0419 - accuracy: 0.9860\n",
      "Epoch 157/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0369 - accuracy: 0.9858\n",
      "Epoch 158/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0431 - accuracy: 0.9875\n",
      "Epoch 159/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0378 - accuracy: 0.9877\n",
      "Epoch 160/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0316 - accuracy: 0.9887\n",
      "Epoch 161/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0379 - accuracy: 0.9861\n",
      "Epoch 162/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0389 - accuracy: 0.9884\n",
      "Epoch 163/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0401 - accuracy: 0.9871\n",
      "Epoch 164/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0376 - accuracy: 0.9880\n",
      "Epoch 165/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0281 - accuracy: 0.9910\n",
      "Epoch 166/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0275 - accuracy: 0.9900\n",
      "Epoch 167/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0367 - accuracy: 0.9872\n",
      "Epoch 168/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0288 - accuracy: 0.9904\n",
      "Epoch 169/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0241 - accuracy: 0.9908\n",
      "Epoch 170/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0266 - accuracy: 0.9923\n",
      "Epoch 171/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0364 - accuracy: 0.9886\n",
      "Epoch 172/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0413 - accuracy: 0.9866\n",
      "Epoch 173/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0314 - accuracy: 0.9895\n",
      "Epoch 174/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0325 - accuracy: 0.9898\n",
      "Epoch 175/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0278 - accuracy: 0.9902\n",
      "Epoch 176/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0319 - accuracy: 0.9890\n",
      "Epoch 177/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0309 - accuracy: 0.9906\n",
      "Epoch 178/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0538 - accuracy: 0.9849\n",
      "Epoch 179/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0264 - accuracy: 0.9916\n",
      "Epoch 180/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0242 - accuracy: 0.9924\n",
      "Epoch 181/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0279 - accuracy: 0.9905\n",
      "Epoch 182/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0300 - accuracy: 0.9916\n",
      "Epoch 183/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0248 - accuracy: 0.9915\n",
      "Epoch 184/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0293 - accuracy: 0.9914\n",
      "Epoch 185/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0447 - accuracy: 0.9852\n",
      "Epoch 186/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0320 - accuracy: 0.9901\n",
      "Epoch 187/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0283 - accuracy: 0.9911\n",
      "Epoch 188/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0280 - accuracy: 0.9911\n",
      "Epoch 189/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0291 - accuracy: 0.9902\n",
      "Epoch 190/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0185 - accuracy: 0.9937\n",
      "Epoch 191/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0267 - accuracy: 0.9911\n",
      "Epoch 192/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0302 - accuracy: 0.9896\n",
      "Epoch 193/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0260 - accuracy: 0.9904\n",
      "Epoch 194/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0267 - accuracy: 0.9918\n",
      "Epoch 195/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0221 - accuracy: 0.9927\n",
      "Epoch 196/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0274 - accuracy: 0.9916\n",
      "Epoch 197/200\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.0336 - accuracy: 0.9887\n",
      "Epoch 198/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0288 - accuracy: 0.9898\n",
      "Epoch 199/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0261 - accuracy: 0.9923\n",
      "Epoch 200/200\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0261 - accuracy: 0.9918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a1c8b9dc30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( \"./dataset/training_set\",\n",
    "                                                    target_size=(64,64), #maintain the network entry\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validator_generator = test_datagen.flow_from_directory(\"./dataset/test_set\",\n",
    "                                                       target_size=(64,64),\n",
    "                                                       batch_size=32,\n",
    "                                                       class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "classifier.fit(train_generator,\n",
    "                         steps_per_epoch=8000//32,\n",
    "                         epochs=200,\n",
    "                         validation_data=validator_generator,\n",
    "                         validation_steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 Convolutional network enhancement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Initialise CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#STEP 1 - Convolución\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3),\n",
    "                      input_shape= (64,64,3), activation=\"relu\"))\n",
    "#STEP 2 - Max Pooling\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#STEP 3 - Convolución\n",
    "classifier.add(Conv2D(filters=32, kernel_size=(3,3),\n",
    "                      activation=\"relu\"))\n",
    "\n",
    "#STEP 4 - Max Pooling\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#STEP 5 - Convolución\n",
    "classifier.add(Conv2D(filters=64, kernel_size=(3,3),\n",
    "                      activation=\"relu\"))\n",
    "\n",
    "#STEP 6 - Max Pooling\n",
    "classifier.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "\n",
    "#STEP 7 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#STEP 8 - Full conection\n",
    "classifier.add(Dense(units=128, activation=\"relu\"))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units=32, activation=\"relu\"))\n",
    "classifier.add(Dropout(rate=0.1))\n",
    "classifier.add(Dense(units=1, activation=\"sigmoid\")) #We use sigmoid to predict if it is a dog or not, in case we have more classes we will use softmax with as many neurons as class.\n",
    "\n",
    "#Compile the neural network \n",
    "classifier.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/80\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.6878 - accuracy: 0.5424 - val_loss: 0.6491 - val_accuracy: 0.6321\n",
      "Epoch 2/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.6315 - accuracy: 0.6520 - val_loss: 0.5927 - val_accuracy: 0.6825\n",
      "Epoch 3/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5706 - accuracy: 0.7072 - val_loss: 0.5137 - val_accuracy: 0.7480\n",
      "Epoch 4/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5336 - accuracy: 0.7326 - val_loss: 0.5205 - val_accuracy: 0.7460\n",
      "Epoch 5/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.5065 - accuracy: 0.7526 - val_loss: 0.4856 - val_accuracy: 0.7555\n",
      "Epoch 6/80\n",
      "250/250 [==============================] - 10s 39ms/step - loss: 0.4769 - accuracy: 0.7696 - val_loss: 0.4785 - val_accuracy: 0.7707\n",
      "Epoch 7/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.4659 - accuracy: 0.7786 - val_loss: 0.4399 - val_accuracy: 0.7918\n",
      "Epoch 8/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.4371 - accuracy: 0.7930 - val_loss: 0.4502 - val_accuracy: 0.7802\n",
      "Epoch 9/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.4269 - accuracy: 0.7985 - val_loss: 0.4260 - val_accuracy: 0.8009\n",
      "Epoch 10/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.4055 - accuracy: 0.8098 - val_loss: 0.4139 - val_accuracy: 0.8075\n",
      "Epoch 11/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3961 - accuracy: 0.8234 - val_loss: 0.4276 - val_accuracy: 0.8014\n",
      "Epoch 12/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3822 - accuracy: 0.8259 - val_loss: 0.4031 - val_accuracy: 0.8140\n",
      "Epoch 13/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3711 - accuracy: 0.8334 - val_loss: 0.3931 - val_accuracy: 0.8211\n",
      "Epoch 14/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3595 - accuracy: 0.8407 - val_loss: 0.3913 - val_accuracy: 0.8261\n",
      "Epoch 15/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.3484 - accuracy: 0.8431 - val_loss: 0.3744 - val_accuracy: 0.8392\n",
      "Epoch 16/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3341 - accuracy: 0.8509 - val_loss: 0.4578 - val_accuracy: 0.7848\n",
      "Epoch 17/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3331 - accuracy: 0.8540 - val_loss: 0.3900 - val_accuracy: 0.8271\n",
      "Epoch 18/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3177 - accuracy: 0.8629 - val_loss: 0.5031 - val_accuracy: 0.7848\n",
      "Epoch 19/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.3112 - accuracy: 0.8621 - val_loss: 0.3880 - val_accuracy: 0.8301\n",
      "Epoch 20/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2928 - accuracy: 0.8720 - val_loss: 0.4750 - val_accuracy: 0.8095\n",
      "Epoch 21/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2938 - accuracy: 0.8725 - val_loss: 0.3988 - val_accuracy: 0.8175\n",
      "Epoch 22/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2725 - accuracy: 0.8840 - val_loss: 0.4812 - val_accuracy: 0.8044\n",
      "Epoch 23/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2675 - accuracy: 0.8844 - val_loss: 0.3730 - val_accuracy: 0.8392\n",
      "Epoch 24/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2644 - accuracy: 0.8871 - val_loss: 0.4268 - val_accuracy: 0.8125\n",
      "Epoch 25/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2551 - accuracy: 0.8907 - val_loss: 0.3873 - val_accuracy: 0.8311\n",
      "Epoch 26/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2495 - accuracy: 0.8947 - val_loss: 0.3963 - val_accuracy: 0.8362\n",
      "Epoch 27/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.2379 - accuracy: 0.8990 - val_loss: 0.3703 - val_accuracy: 0.8407\n",
      "Epoch 28/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2282 - accuracy: 0.9061 - val_loss: 0.3869 - val_accuracy: 0.8377\n",
      "Epoch 29/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2327 - accuracy: 0.9001 - val_loss: 0.4176 - val_accuracy: 0.8448\n",
      "Epoch 30/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2185 - accuracy: 0.9110 - val_loss: 0.4502 - val_accuracy: 0.8377\n",
      "Epoch 31/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2103 - accuracy: 0.9119 - val_loss: 0.4247 - val_accuracy: 0.8276\n",
      "Epoch 32/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.2024 - accuracy: 0.9171 - val_loss: 0.4332 - val_accuracy: 0.8332\n",
      "Epoch 33/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1987 - accuracy: 0.9218 - val_loss: 0.4324 - val_accuracy: 0.8422\n",
      "Epoch 34/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1867 - accuracy: 0.9244 - val_loss: 0.4550 - val_accuracy: 0.8337\n",
      "Epoch 35/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1914 - accuracy: 0.9247 - val_loss: 0.4137 - val_accuracy: 0.8493\n",
      "Epoch 36/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1799 - accuracy: 0.9273 - val_loss: 0.4429 - val_accuracy: 0.8432\n",
      "Epoch 37/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1851 - accuracy: 0.9271 - val_loss: 0.4460 - val_accuracy: 0.8251\n",
      "Epoch 38/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1707 - accuracy: 0.9321 - val_loss: 0.4513 - val_accuracy: 0.8392\n",
      "Epoch 39/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1719 - accuracy: 0.9285 - val_loss: 0.4539 - val_accuracy: 0.8311\n",
      "Epoch 40/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1548 - accuracy: 0.9386 - val_loss: 0.4883 - val_accuracy: 0.8367\n",
      "Epoch 41/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1664 - accuracy: 0.9290 - val_loss: 0.4998 - val_accuracy: 0.8327\n",
      "Epoch 42/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1477 - accuracy: 0.9414 - val_loss: 0.5275 - val_accuracy: 0.8407\n",
      "Epoch 43/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1438 - accuracy: 0.9439 - val_loss: 0.5621 - val_accuracy: 0.8367\n",
      "Epoch 44/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1562 - accuracy: 0.9371 - val_loss: 0.5461 - val_accuracy: 0.8332\n",
      "Epoch 45/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1356 - accuracy: 0.9474 - val_loss: 0.4994 - val_accuracy: 0.8397\n",
      "Epoch 46/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1488 - accuracy: 0.9441 - val_loss: 0.4585 - val_accuracy: 0.8493\n",
      "Epoch 47/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1358 - accuracy: 0.9486 - val_loss: 0.4828 - val_accuracy: 0.8397\n",
      "Epoch 48/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1358 - accuracy: 0.9465 - val_loss: 0.5699 - val_accuracy: 0.8347\n",
      "Epoch 49/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1287 - accuracy: 0.9476 - val_loss: 0.5086 - val_accuracy: 0.8311\n",
      "Epoch 50/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1251 - accuracy: 0.9513 - val_loss: 0.5110 - val_accuracy: 0.8417\n",
      "Epoch 51/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1269 - accuracy: 0.9504 - val_loss: 0.5394 - val_accuracy: 0.8397\n",
      "Epoch 52/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1119 - accuracy: 0.9548 - val_loss: 0.5292 - val_accuracy: 0.8357\n",
      "Epoch 53/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1160 - accuracy: 0.9539 - val_loss: 0.5598 - val_accuracy: 0.8367\n",
      "Epoch 54/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1272 - accuracy: 0.9510 - val_loss: 0.5438 - val_accuracy: 0.8296\n",
      "Epoch 55/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1125 - accuracy: 0.9579 - val_loss: 0.5830 - val_accuracy: 0.8432\n",
      "Epoch 56/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1158 - accuracy: 0.9550 - val_loss: 0.5715 - val_accuracy: 0.8347\n",
      "Epoch 57/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1149 - accuracy: 0.9556 - val_loss: 0.5827 - val_accuracy: 0.8276\n",
      "Epoch 58/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1170 - accuracy: 0.9556 - val_loss: 0.5255 - val_accuracy: 0.8478\n",
      "Epoch 59/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1084 - accuracy: 0.9586 - val_loss: 0.5934 - val_accuracy: 0.8508\n",
      "Epoch 60/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1078 - accuracy: 0.9578 - val_loss: 0.5676 - val_accuracy: 0.8377\n",
      "Epoch 61/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.1099 - accuracy: 0.9589 - val_loss: 0.5313 - val_accuracy: 0.8327\n",
      "Epoch 62/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0904 - accuracy: 0.9678 - val_loss: 0.5823 - val_accuracy: 0.8438\n",
      "Epoch 63/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.1042 - accuracy: 0.9621 - val_loss: 0.5921 - val_accuracy: 0.8317\n",
      "Epoch 64/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0973 - accuracy: 0.9632 - val_loss: 0.5688 - val_accuracy: 0.8513\n",
      "Epoch 65/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0941 - accuracy: 0.9638 - val_loss: 0.6101 - val_accuracy: 0.8422\n",
      "Epoch 66/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0959 - accuracy: 0.9640 - val_loss: 0.6121 - val_accuracy: 0.8357\n",
      "Epoch 67/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0934 - accuracy: 0.9653 - val_loss: 0.5906 - val_accuracy: 0.8432\n",
      "Epoch 68/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0896 - accuracy: 0.9656 - val_loss: 0.6154 - val_accuracy: 0.8367\n",
      "Epoch 69/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0957 - accuracy: 0.9615 - val_loss: 0.6564 - val_accuracy: 0.8301\n",
      "Epoch 70/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0943 - accuracy: 0.9671 - val_loss: 0.5659 - val_accuracy: 0.8402\n",
      "Epoch 71/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0892 - accuracy: 0.9659 - val_loss: 0.5849 - val_accuracy: 0.8438\n",
      "Epoch 72/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0822 - accuracy: 0.9718 - val_loss: 0.6655 - val_accuracy: 0.8372\n",
      "Epoch 73/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0744 - accuracy: 0.9720 - val_loss: 0.6977 - val_accuracy: 0.8327\n",
      "Epoch 74/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0879 - accuracy: 0.9659 - val_loss: 0.6212 - val_accuracy: 0.8417\n",
      "Epoch 75/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0935 - accuracy: 0.9675 - val_loss: 0.5883 - val_accuracy: 0.8443\n",
      "Epoch 76/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0844 - accuracy: 0.9680 - val_loss: 0.6315 - val_accuracy: 0.8306\n",
      "Epoch 77/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0768 - accuracy: 0.9714 - val_loss: 0.6575 - val_accuracy: 0.8387\n",
      "Epoch 78/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0807 - accuracy: 0.9694 - val_loss: 0.5616 - val_accuracy: 0.8473\n",
      "Epoch 79/80\n",
      "250/250 [==============================] - 10s 38ms/step - loss: 0.0749 - accuracy: 0.9730 - val_loss: 0.6331 - val_accuracy: 0.8458\n",
      "Epoch 80/80\n",
      "250/250 [==============================] - 9s 38ms/step - loss: 0.0774 - accuracy: 0.9732 - val_loss: 0.6475 - val_accuracy: 0.8206\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a1c479ecb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We repeat the steps with the images for a better understanding of the problem.\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale= 1./255,\n",
    "    shear_range= 0.2,\n",
    "    zoom_range= 0.2,\n",
    "    horizontal_flip= True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( \"./dataset/training_set\",\n",
    "                                                    target_size=(64,64), \n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "validator_generator = test_datagen.flow_from_directory(\"./dataset/test_set\",\n",
    "                                                       target_size=(64,64),\n",
    "                                                       batch_size=32,\n",
    "                                                       class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "classifier.fit(train_generator,\n",
    "                         steps_per_epoch=8000//32, # images // number of batches\n",
    "                         epochs=80,\n",
    "                         validation_data=validator_generator,\n",
    "                         validation_steps=2000//32) # images // number of batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 12ms/step\n",
      "[[1.]]\n",
      "{'cats': 0, 'dogs': 1}\n",
      "It is a dog\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Particular use case\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image \n",
    "\n",
    "\n",
    "test_image = image.load_img(\"./Predict/test_1/nyme.jpg\", target_size=(64,64))\n",
    "plt.imshow(test_image)\n",
    "\n",
    "test_image = image.img_to_array(test_image) # Now with this we make it have 3 channels\n",
    "test_image = np.expand_dims(test_image, axis=0 ) # Extra batch size for predictors\n",
    "result = classifier.predict(test_image)\n",
    "print(result)\n",
    "print(train_generator.class_indices)\n",
    "if result[0][0] == 1:\n",
    "    print(\"It is a dog\")\n",
    "else:\n",
    "    print(\"It is a cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
